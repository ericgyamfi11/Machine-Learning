{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.16595599]\n",
      " [ 0.44064899]\n",
      " [-0.99977125]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class MyNNetwork():\n",
    "    \n",
    "    def __init__(self):\n",
    "        # seeding for random number generation\n",
    "        np.random.seed(1)\n",
    "        \n",
    "        #converting weights to a 3 by 1 matrix with values from -1 to 1 and mean of 0\n",
    "        self.synaptic_weights = 2 * np.random.random((3, 1)) - 1\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        #applying the sigmoid function\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        #computing derivative to the Sigmoid function\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def fit(self, X, Y, training_iterations):\n",
    "        \n",
    "        #training the model to make accurate predictions while adjusting weights continually\n",
    "        for iteration in range(training_iterations):\n",
    "            #siphon the training data via  the neuron\n",
    "            output = self.predict(X)\n",
    "\n",
    "            #computing error rate for back-propagation\n",
    "            error = Y - output\n",
    "            \n",
    "            #performing weight adjustments\n",
    "            adjust = np.dot(Y.T, error * self.sigmoid_derivative(output))\n",
    "\n",
    "            self.synaptic_weights += adjust\n",
    "\n",
    "    def predict(self, new_x):\n",
    "        #passing the inputs via the neuron to get output   \n",
    "        #converting values to floats\n",
    "        \n",
    "        new_x = new_x.astype(float)\n",
    "        output = self.sigmoid(np.dot(new_x, self.synaptic_weights))\n",
    "        return output\n",
    "if __name__ == \"__main__\":\n",
    "    #initializing the neuron class\n",
    "    neural_network = MyNNetwork()\n",
    "    print(neural_network.synaptic_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing the neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ending Weights After Training: \n",
      "[[3.4386924 ]\n",
      " [4.04529737]\n",
      " [2.60487714]]\n",
      "[[0.99870788]\n",
      " [0.9311748 ]]\n",
      "Wow, we did it!\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0,0,1],[1,1,1],[1,0,1],[0,1,1]])\n",
    "Y = np.array([[0,1,1,0]]).T\n",
    "\n",
    "#training taking place\n",
    "neural_network.fit(X, Y, 15000)\n",
    "\n",
    "print(\"Ending Weights After Training: \")\n",
    "print(neural_network.synaptic_weights)\n",
    "q = np.array([[0,1,1], [0,0,1]])\n",
    "print(neural_network.predict(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
